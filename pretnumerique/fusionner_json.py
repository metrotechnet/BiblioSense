#!/usr/bin/env python3
"""
Script pour fusionner tous les fichiers JSON du dossier pretnumerique
en un seul fichier JSON consolidÃ© avec des statistiques dÃ©taillÃ©es.
"""

import json
import os
from pathlib import Path
from collections import defaultdict
import datetime

def load_json_file(file_path):
    """Charge un fichier JSON et retourne son contenu."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                return [data]  # Convert single dict to list
            else:
                print(f"âš ï¸  Format inattendu dans {file_path}: {type(data)}")
                return []
    except json.JSONDecodeError as e:
        print(f"âŒ Erreur JSON dans {file_path}: {e}")
        return []
    except FileNotFoundError:
        print(f"âŒ Fichier non trouvÃ©: {file_path}")
        return []
    except Exception as e:
        print(f"âŒ Erreur lors du chargement de {file_path}: {e}")
        return []

def get_category_from_filename(filename):
    """Extrait le nom de la catÃ©gorie du nom de fichier."""
    return filename.replace('.json', '').replace('_', ' ')

def validate_book_data(book, source_file):
    """Valide et nettoie les donnÃ©es d'un livre."""
    if not isinstance(book, dict):
        print(f"âš ï¸  Livre non valide dans {source_file}: {type(book)}")
        return None
    
    # Champs obligatoires
    required_fields = ['titre']
    for field in required_fields:
        if field not in book or not book[field]:
            print(f"âš ï¸  Livre sans {field} dans {source_file}: {book}")
            return None
    
    # Nettoyer et standardiser les donnÃ©es
    cleaned_book = {}
    for key, value in book.items():
        if isinstance(value, str):
            cleaned_book[key] = value.strip()
        else:
            cleaned_book[key] = value
    
    # Ajouter la source du fichier
    cleaned_book['source_fichier'] = source_file
    
    return cleaned_book

def remove_duplicates(all_books):
    """Supprime les doublons basÃ©s sur le titre et l'auteur."""
    print("\nğŸ” Recherche et suppression des doublons...")
    
    seen_books = {}  # Dictionnaire pour stocker les livres dÃ©jÃ  vus
    unique_books = []
    duplicates_found = []
    
    for book in all_books:
        # CrÃ©er une clÃ© unique basÃ©e sur titre et auteur (normalisÃ©s)
        titre = book.get('titre', '').strip().lower()
        auteur = book.get('auteur', '').strip().lower()
        
        # Nettoyer l'auteur (enlever les mentions comme "(Auteur)", "(Narrateur)", etc.)
        import re
        auteur_clean = re.sub(r'\([^)]*\)', '', auteur).strip()
        
        # CrÃ©er la clÃ© unique
        unique_key = f"{titre}|||{auteur_clean}"
        
        if unique_key in seen_books:
            # Doublon trouvÃ©
            original_book = seen_books[unique_key]
            duplicate_info = {
                'titre': book.get('titre', ''),
                'auteur': book.get('auteur', ''),
                'source_original': original_book.get('source_fichier', ''),
                'source_doublon': book.get('source_fichier', ''),
                'lien_original': original_book.get('lien', ''),
                'lien_doublon': book.get('lien', '')
            }
            duplicates_found.append(duplicate_info)
            
            # Choisir le meilleur livre Ã  conserver (celui avec le plus d'informations)
            original_score = sum(1 for v in original_book.values() if v and str(v).strip())
            current_score = sum(1 for v in book.values() if v and str(v).strip())
            
            if current_score > original_score:
                # Le livre actuel a plus d'informations, remplacer l'original
                seen_books[unique_key] = book
                # Mettre Ã  jour la liste des livres uniques
                for i, unique_book in enumerate(unique_books):
                    if unique_book is original_book:
                        unique_books[i] = book
                        break
                print(f"   ğŸ“ Doublon remplacÃ©: '{book.get('titre', '')}' - Nouvelle source: {book.get('source_fichier', '')}")
            else:
                print(f"   ğŸ”„ Doublon ignorÃ©: '{book.get('titre', '')}' de {book.get('source_fichier', '')}")
        else:
            # Nouveau livre unique
            seen_books[unique_key] = book
            unique_books.append(book)
    
    print(f"\nğŸ“Š RÃ‰SULTATS DE LA DÃ‰DUPLICATION:")
    print(f"   ğŸ“š Livres originaux: {len(all_books)}")
    print(f"   âœ… Livres uniques: {len(unique_books)}")
    print(f"   ğŸ”„ Doublons supprimÃ©s: {len(duplicates_found)}")
    
    # Afficher les doublons trouvÃ©s pour information
    if duplicates_found:
        print(f"\nğŸ“‹ DOUBLONS DÃ‰TECTÃ‰S:")
        for i, dup in enumerate(duplicates_found[:10], 1):  # Afficher les 10 premiers
            print(f"   {i:2d}. '{dup['titre']}' par {dup['auteur']}")
            print(f"       ğŸ“ Sources: {dup['source_original']} âœ {dup['source_doublon']}")
        
        if len(duplicates_found) > 10:
            print(f"   ... et {len(duplicates_found) - 10} autres doublons")
    
    return unique_books, duplicates_found

def generate_statistics(all_books, duplicates_info=None):
    """GÃ©nÃ¨re des statistiques dÃ©taillÃ©es sur les livres."""
    stats = {
        'total_livres': len(all_books),
        'par_categorie': defaultdict(int),
        'par_editeur': defaultdict(int),
        'par_langue': defaultdict(int),
        'par_annee': defaultdict(int),
        'avec_couverture': 0,
        'sans_couverture': 0,
        'avec_resume': 0,
        'sans_resume': 0,
        'date_fusion': datetime.datetime.now().isoformat()
    }
    
    # Ajouter les statistiques de dÃ©duplication si disponibles
    if duplicates_info:
        stats['deduplication'] = {
            'doublons_trouves': len(duplicates_info),
            'doublons_details': duplicates_info
        }
    
    for book in all_books:
        # Statistiques par catÃ©gorie
        categorie = book.get('categorie', 'Non dÃ©finie')
        stats['par_categorie'][categorie] += 1
        
        # Statistiques par Ã©diteur
        editeur = book.get('editeur', 'Non dÃ©fini')
        stats['par_editeur'][editeur] += 1
        
        # Statistiques par langue
        langue = book.get('langue', 'Non dÃ©finie')
        stats['par_langue'][langue] += 1
        
        # Statistiques par annÃ©e de parution
        parution = book.get('parution', '')
        if parution:
            # Extraire l'annÃ©e (format peut Ãªtre "Janvier 2024", "2024", etc.)
            try:
                # Chercher un nombre de 4 chiffres dans la chaÃ®ne
                import re
                year_match = re.search(r'\b(20\d{2})\b', parution)
                if year_match:
                    year = year_match.group(1)
                    stats['par_annee'][year] += 1
            except:
                pass
        
        # Statistiques couverture et rÃ©sumÃ©
        if book.get('couverture') and book['couverture'].strip():
            stats['avec_couverture'] += 1
        else:
            stats['sans_couverture'] += 1
            
        if book.get('resume') and book['resume'].strip():
            stats['avec_resume'] += 1
        else:
            stats['sans_resume'] += 1
    
    # Convertir defaultdict en dict normal pour la sÃ©rialisation JSON
    stats['par_categorie'] = dict(stats['par_categorie'])
    stats['par_editeur'] = dict(stats['par_editeur'])
    stats['par_langue'] = dict(stats['par_langue'])
    stats['par_annee'] = dict(stats['par_annee'])
    
    return stats

def main():
    """Fonction principale pour fusionner les fichiers JSON."""
    print("ğŸ”„ DÃ©but de la fusion des fichiers JSON PrÃªt numÃ©rique...")
    print("=" * 60)
    
    # DÃ©finir les chemins (script exÃ©cutÃ© depuis le dossier pretnumerique)
    pretnumerique_dir = Path(".")  # Dossier courant
    output_file = "../dbase/prenumerique_complet.json"
    stats_file = "../dbase/prenumerique_statistiques.json"
    
    # VÃ©rifier que le dossier pretnumerique existe
    if not pretnumerique_dir.exists():
        print(f"âŒ Le dossier {pretnumerique_dir} n'existe pas.")
        return
    
    # CrÃ©er le dossier dbase s'il n'existe pas
    Path("../dbase").mkdir(exist_ok=True)
    
    # Collecter tous les fichiers JSON
    json_files = list(pretnumerique_dir.glob("*.json"))
    
    if not json_files:
        print(f"âŒ Aucun fichier JSON trouvÃ© dans {pretnumerique_dir}")
        return
    
    print(f"ğŸ“ {len(json_files)} fichiers JSON trouvÃ©s:")
    for file in sorted(json_files):
        print(f"   - {file.name}")
    print()
    
    # Fusionner tous les livres
    all_books = []
    file_stats = {}
    
    for json_file in sorted(json_files):
        print(f"â³ Traitement de {json_file.name}...")
        
        books = load_json_file(json_file)
        valid_books = []
        
        for book in books:
            validated_book = validate_book_data(book, json_file.name)
            if validated_book:
                valid_books.append(validated_book)
        
        file_stats[json_file.name] = {
            'total_brut': len(books),
            'total_valide': len(valid_books),
            'categorie': get_category_from_filename(json_file.stem)
        }
        
        all_books.extend(valid_books)
        print(f"   âœ… {len(valid_books)} livres valides sur {len(books)} trouvÃ©s")
    
    print(f"\nğŸ“Š RÃ‰SULTATS DE LA FUSION:")
    print(f"   ğŸ“š Total de livres fusionnÃ©s: {len(all_books)}")
    print(f"   ğŸ“ Fichiers traitÃ©s: {len(json_files)}")
    
    # Supprimer les doublons
    unique_books, duplicates_found = remove_duplicates(all_books)
    
    # GÃ©nÃ©rer les statistiques
    print("\nâ³ GÃ©nÃ©ration des statistiques...")
    stats = generate_statistics(unique_books, duplicates_found)
    
    # Ajouter les statistiques par fichier
    stats['par_fichier'] = file_stats
    
    # Sauvegarder le fichier fusionnÃ© (avec les livres uniques)
    print(f"\nğŸ’¾ Sauvegarde dans {output_file}...")
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(unique_books, f, ensure_ascii=False, indent=2)
        print(f"   âœ… Fichier fusionnÃ© sauvegardÃ©: {output_file}")
    except Exception as e:
        print(f"   âŒ Erreur lors de la sauvegarde: {e}")
        return
    
    # Sauvegarder les statistiques
    print(f"ğŸ’¾ Sauvegarde des statistiques dans {stats_file}...")
    try:
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        print(f"   âœ… Statistiques sauvegardÃ©es: {stats_file}")
    except Exception as e:
        print(f"   âŒ Erreur lors de la sauvegarde des statistiques: {e}")
    
    # Affichage des statistiques principales
    print(f"\nğŸ“ˆ STATISTIQUES PRINCIPALES:")
    print(f"   ğŸ“š Total de livres: {stats['total_livres']}")
    if 'deduplication' in stats:
        print(f"   ğŸ”„ Doublons supprimÃ©s: {stats['deduplication']['doublons_trouves']}")
    print(f"   ğŸ·ï¸  CatÃ©gories: {len(stats['par_categorie'])}")
    print(f"   ğŸ¢ Ã‰diteurs: {len(stats['par_editeur'])}")
    print(f"   ğŸŒ Langues: {len(stats['par_langue'])}")
    print(f"   ğŸ“… AnnÃ©es: {len(stats['par_annee'])}")
    print(f"   ğŸ–¼ï¸  Avec couverture: {stats['avec_couverture']} ({stats['avec_couverture']/stats['total_livres']*100:.1f}%)")
    print(f"   ğŸ“– Avec rÃ©sumÃ©: {stats['avec_resume']} ({stats['avec_resume']/stats['total_livres']*100:.1f}%)")
    
    # Top 10 des catÃ©gories
    print(f"\nğŸ† TOP 10 DES CATÃ‰GORIES:")
    sorted_categories = sorted(stats['par_categorie'].items(), key=lambda x: x[1], reverse=True)
    for i, (cat, count) in enumerate(sorted_categories[:10], 1):
        print(f"   {i:2d}. {cat}: {count} livres")
    
    # Top 10 des Ã©diteurs
    print(f"\nğŸ† TOP 10 DES Ã‰DITEURS:")
    sorted_editors = sorted(stats['par_editeur'].items(), key=lambda x: x[1], reverse=True)
    for i, (editor, count) in enumerate(sorted_editors[:10], 1):
        print(f"   {i:2d}. {editor}: {count} livres")
    
    print(f"\n" + "=" * 60)
    print(f"ğŸ‰ Fusion terminÃ©e avec succÃ¨s!")
    print(f"ğŸ“„ Fichier fusionnÃ©: {output_file}")
    print(f"ğŸ“Š Statistiques: {stats_file}")
    print(f"=" * 60)

if __name__ == "__main__":
    main()
