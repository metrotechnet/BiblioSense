import requests
import json
import time
import random

# =======================
# CONFIGURATION
# =======================
SEARCH_URL = "https://openlibrary.org/search.json"
WORK_URL = "https://openlibrary.org/works/"
OUTPUT_FILE = "openlibrary_livres_francais.json"
TOTAL_BOOKS = 10000   # Nombre total de livres √† r√©cup√©rer
BATCH_SIZE = 50     # R√©duit pour √©viter les erreurs serveur
MAX_RETRIES = 3     # Nombre de tentatives max
DELAY_BETWEEN_REQUESTS = 1  # D√©lai entre requ√™tes
# =======================

def fetch_books(start, limit):
    """R√©cup√®re un lot de livres r√©cents avec gestion d'erreurs robuste"""
    for attempt in range(MAX_RETRIES):
        try:
            # Utiliser une requ√™te sp√©cifique pour les livres en fran√ßais uniquement
            params = {
                "q": "language:fre",  # Uniquement les livres en fran√ßais
                "sort": "new",  # Plus stable que "first_publish_year desc"
                "limit": limit,
                "offset": start,
                "fields": "key,title,author_name,first_publish_year,subject,publisher,number_of_pages_median,language,cover_i"
            }
            
            print(f"  Tentative {attempt + 1}/{MAX_RETRIES} pour offset {start}...")
            
            # Headers pour √©viter le rate limiting
            headers = {
                'User-Agent': 'BiblioSense/1.0 ',
                'Accept': 'application/json'
            }
            
            r = requests.get(SEARCH_URL, params=params, headers=headers, timeout=30)
            
            if r.status_code == 200:
                return r.json()
            elif r.status_code == 500:
                print(f"  Erreur 500 - Tentative {attempt + 1}, attente {2 ** attempt}s...")
                time.sleep(2 ** attempt)  # Backoff exponentiel
                continue
            else:
                r.raise_for_status()
                
        except requests.exceptions.RequestException as e:
            print(f"  Erreur de requ√™te: {e}")
            if attempt < MAX_RETRIES - 1:
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"  Attente {wait_time:.1f}s avant nouvelle tentative...")
                time.sleep(wait_time)
            else:
                print(f"  √âchec apr√®s {MAX_RETRIES} tentatives")
                return {"docs": []}  # Retourner structure vide
    
    return {"docs": []}  # Si toutes les tentatives √©chouent

def save_books_to_file(books, filename):
    """Sauvegarde les livres dans le fichier JSON"""
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(books, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde: {e}")
        return False

def load_existing_books(filename):
    """Charge les livres existants depuis le fichier si il existe"""
    try:
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"üìÑ Nouveau fichier: {filename}")
        return []
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lecture fichier existant: {e}")
        return []

def fetch_book_details(work_key):
    """R√©cup√®re les d√©tails d'un livre avec gestion d'erreurs"""
    try:
        url = f"https://openlibrary.org{work_key}.json"
        headers = {
            'User-Agent': 'BiblioSense/1.0 (https://github.com/metrotechnet/BiblioSense)'
        }
        r = requests.get(url, headers=headers, timeout=15)
        if r.status_code == 200:
            return r.json()
    except requests.exceptions.RequestException as e:
        print(f"    Erreur d√©tails pour {work_key}: {e}")
    return {}

def extract_metadata(doc):
    """Extrait les champs demand√©s"""
    title = doc.get("title", "Inconnu")
    author = ", ".join(doc.get("author_name", [])) if "author_name" in doc else "Inconnu"
    book_link = f"https://openlibrary.org{doc.get('key', '')}"
    category = ", ".join(doc.get("subject", [])[:5]) if "subject" in doc else ""
    editor = ", ".join(doc.get("publisher", [])[:3]) if "publisher" in doc else ""
    parution = doc.get("first_publish_year", "Inconnu")
    pages = doc.get("number_of_pages_median", "")
    langue = ", ".join(doc.get("language", [])) if "language" in doc else ""
    cover_url = f"https://covers.openlibrary.org/b/id/{doc['cover_i']}-L.jpg" if "cover_i" in doc else ""

    # --- R√©cup√©rer r√©sum√© et pages via l'API d√©taill√©e ---
    details = fetch_book_details(doc.get("key", ""))
    summary = ""
    if details:
        if isinstance(details.get("description"), dict):
            summary = details["description"].get("value", "")
        elif isinstance(details.get("description"), str):
            summary = details["description"]
        # Parfois pages dispo dans 'details'
        pages = details.get("number_of_pages", pages)

    return {
        "titre": title,
        "auteur": author,
        "resume": summary,
        "lien": book_link,
        "categorie": category,
        "editeur": editor,
        "parution": parution,
        "pages": pages,
        "langue": langue,
        "couverture": cover_url
    }

def main():
    # Charger les livres existants si le fichier existe d√©j√†
    all_books = load_existing_books(OUTPUT_FILE)
    books_already_loaded = len(all_books)
    
    successful_batches = 0
    failed_batches = 0
    
    print(f"üöÄ D√©but extraction de {TOTAL_BOOKS} livres fran√ßais (par lots de {BATCH_SIZE})...")
    print(f"üì° D√©lai entre requ√™tes: {DELAY_BETWEEN_REQUESTS}s")
    print(f"üá´üá∑ Recherche: livres en fran√ßais uniquement")
    
    if books_already_loaded > 0:
        print(f"üìö {books_already_loaded} livres d√©j√† pr√©sents dans {OUTPUT_FILE}")
        print(f"‚ñ∂Ô∏è  Reprise depuis le livre {books_already_loaded + 1}")
    
    for start in range(0, TOTAL_BOOKS, BATCH_SIZE):
        current_batch_size = min(BATCH_SIZE, TOTAL_BOOKS - start)
        print(f"\nüìñ Lot {start // BATCH_SIZE + 1}: livres {start + 1} √† {start + current_batch_size}...")
        
        data = fetch_books(start, current_batch_size)
        docs = data.get("docs", [])
        
        if docs:
            successful_batches += 1
            print(f"‚úÖ {len(docs)} livres r√©cup√©r√©s dans ce lot")
            
            batch_books = []  # Livres du lot actuel
            
            for i, doc in enumerate(docs):
                try:
                    book_data = extract_metadata(doc)
                    batch_books.append(book_data)
                    
                    # Progress indicator
                    if (i + 1) % 10 == 0:
                        print(f"   Trait√© {i + 1}/{len(docs)} livres du lot...")
                        
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Erreur traitement livre: {e}")
                    continue
                
                # D√©lai pour √©viter le rate limiting
                time.sleep(0.2)
            
            # Ajouter les nouveaux livres du lot √† la liste compl√®te
            all_books.extend(batch_books)
            
            # Sauvegarder apr√®s chaque lot r√©ussi
            if save_books_to_file(all_books, OUTPUT_FILE):
                print(f"üíæ Sauvegarde interm√©diaire: {len(all_books)} livres total")
            else:
                print(f"‚ùå √âchec sauvegarde - continuant quand m√™me...")
                
        else:
            failed_batches += 1
            print(f"‚ùå √âchec r√©cup√©ration du lot {start // BATCH_SIZE + 1}")
        
        # D√©lai entre lots
        if start + BATCH_SIZE < TOTAL_BOOKS:
            print(f"‚è≥ Attente {DELAY_BETWEEN_REQUESTS}s avant le prochain lot...")
            time.sleep(DELAY_BETWEEN_REQUESTS)

    # Statistiques finales
    new_books = len(all_books) - books_already_loaded
    print(f"\nüìä Extraction termin√©e:")
    print(f"   ‚úÖ Lots r√©ussis: {successful_batches}")
    print(f"   ‚ùå Lots √©chou√©s: {failed_batches}")
    print(f"   üìö Nouveaux livres ajout√©s: {new_books}")
    print(f"   üìö Total livres dans le fichier: {len(all_books)}")

    # Sauvegarde finale (surtout utile si aucun lot n'a r√©ussi)
    if all_books:
        if save_books_to_file(all_books, OUTPUT_FILE):
            print(f"üíæ Sauvegarde finale r√©ussie dans {OUTPUT_FILE}")
        else:
            print(f"‚ùå √âchec sauvegarde finale")
    else:
        print("‚ö†Ô∏è  Aucun livre r√©cup√©r√© - pas de fichier g√©n√©r√©")

if __name__ == "__main__":
    main()

