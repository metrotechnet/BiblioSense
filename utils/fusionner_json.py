#!/usr/bin/env python3
"""
Script pour fusionner tous les fichiers JSON du dossier pretnumerique
en un seul fichier JSON consolid√© avec des statistiques d√©taill√©es.
"""

import json
import os
from pathlib import Path
from collections import defaultdict
import datetime

def load_json_file(file_path):
    """Charge un fichier JSON et retourne son contenu."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                return [data]  # Convert single dict to list
            else:
                print(f"‚ö†Ô∏è  Format inattendu dans {file_path}: {type(data)}")
                return []
    except json.JSONDecodeError as e:
        print(f"‚ùå Erreur JSON dans {file_path}: {e}")
        return []
    except FileNotFoundError:
        print(f"‚ùå Fichier non trouv√©: {file_path}")
        return []
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement de {file_path}: {e}")
        return []

def get_category_from_filename(filename):
    """Extrait le nom de la cat√©gorie du nom de fichier."""
    return filename.replace('.json', '').replace('_', ' ')

def validate_book_data(book, source_file):
    """Valide et nettoie les donn√©es d'un livre."""
    if not isinstance(book, dict):
        print(f"‚ö†Ô∏è  Livre non valide dans {source_file}: {type(book)}")
        return None
    
    # Champs obligatoires
    required_fields = ['titre']
    for field in required_fields:
        if field not in book or not book[field]:
            print(f"‚ö†Ô∏è  Livre sans {field} dans {source_file}: {book}")
            return None
    
    # Nettoyer et standardiser les donn√©es
    cleaned_book = {}
    for key, value in book.items():
        if isinstance(value, str):
            cleaned_book[key] = value.strip()
        else:
            cleaned_book[key] = value
    
    # Ajouter la source du fichier
    cleaned_book['source_fichier'] = source_file
    
    return cleaned_book

def remove_duplicates(all_books):
    """Supprime les doublons bas√©s sur le titre et l'auteur."""
    print("\nüîç Recherche et suppression des doublons...")
    
    seen_books = {}  # Dictionnaire pour stocker les livres d√©j√† vus
    unique_books = []
    duplicates_found = []
    
    for book in all_books:
        # Cr√©er une cl√© unique bas√©e sur titre et auteur (normalis√©s)
        titre = book.get('titre', '').strip().lower()
        auteur = book.get('auteur', '').strip().lower()
        
        # Nettoyer l'auteur (enlever les mentions comme "(Auteur)", "(Narrateur)", etc.)
        import re
        auteur_clean = re.sub(r'\([^)]*\)', '', auteur).strip()
        
        # Cr√©er la cl√© unique
        unique_key = f"{titre}|||{auteur_clean}"
        
        if unique_key in seen_books:
            # Doublon trouv√©
            original_book = seen_books[unique_key]
            duplicate_info = {
                'titre': book.get('titre', ''),
                'auteur': book.get('auteur', ''),
                'source_original': original_book.get('source_fichier', ''),
                'source_doublon': book.get('source_fichier', ''),
                'lien_original': original_book.get('lien', ''),
                'lien_doublon': book.get('lien', '')
            }
            duplicates_found.append(duplicate_info)
            
            # Choisir le meilleur livre √† conserver (celui avec le plus d'informations)
            original_score = sum(1 for v in original_book.values() if v and str(v).strip())
            current_score = sum(1 for v in book.values() if v and str(v).strip())
            
            if current_score > original_score:
                # Le livre actuel a plus d'informations, remplacer l'original
                seen_books[unique_key] = book
                # Mettre √† jour la liste des livres uniques
                for i, unique_book in enumerate(unique_books):
                    if unique_book is original_book:
                        unique_books[i] = book
                        break
                print(f"   üìù Doublon remplac√©: '{book.get('titre', '')}' - Nouvelle source: {book.get('source_fichier', '')}")
            else:
                print(f"   üîÑ Doublon ignor√©: '{book.get('titre', '')}' de {book.get('source_fichier', '')}")
        else:
            # Nouveau livre unique
            seen_books[unique_key] = book
            unique_books.append(book)
    
    print(f"\nüìä R√âSULTATS DE LA D√âDUPLICATION:")
    print(f"   üìö Livres originaux: {len(all_books)}")
    print(f"   ‚úÖ Livres uniques: {len(unique_books)}")
    print(f"   üîÑ Doublons supprim√©s: {len(duplicates_found)}")
    
    # Afficher les doublons trouv√©s pour information
    if duplicates_found:
        print(f"\nüìã DOUBLONS D√âTECT√âS:")
        for i, dup in enumerate(duplicates_found[:10], 1):  # Afficher les 10 premiers
            print(f"   {i:2d}. '{dup['titre']}' par {dup['auteur']}")
            print(f"       üìÅ Sources: {dup['source_original']} ‚ûú {dup['source_doublon']}")
        
        if len(duplicates_found) > 10:
            print(f"   ... et {len(duplicates_found) - 10} autres doublons")
    
    return unique_books, duplicates_found

def generate_statistics(all_books, duplicates_info=None):
    """G√©n√®re des statistiques d√©taill√©es sur les livres."""
    stats = {
        'total_livres': len(all_books),
        'par_categorie': defaultdict(int),
        'par_editeur': defaultdict(int),
        'par_langue': defaultdict(int),
        'par_annee': defaultdict(int),
        'avec_couverture': 0,
        'sans_couverture': 0,
        'avec_resume': 0,
        'sans_resume': 0,
        'date_fusion': datetime.datetime.now().isoformat()
    }
    
    # Ajouter les statistiques de d√©duplication si disponibles
    if duplicates_info:
        stats['deduplication'] = {
            'doublons_trouves': len(duplicates_info),
            'doublons_details': duplicates_info
        }
    
    for book in all_books:
        # Statistiques par cat√©gorie
        categorie = book.get('categorie', 'Non d√©finie')
        stats['par_categorie'][categorie] += 1
        
        # Statistiques par √©diteur
        editeur = book.get('editeur', 'Non d√©fini')
        stats['par_editeur'][editeur] += 1
        
        # Statistiques par langue
        langue = book.get('langue', 'Non d√©finie')
        stats['par_langue'][langue] += 1
        
        # Statistiques par ann√©e de parution
        parution = book.get('parution', '')
        if parution:
            # Extraire l'ann√©e (format peut √™tre "Janvier 2024", "2024", etc.)
            try:
                # Chercher un nombre de 4 chiffres dans la cha√Æne
                import re
                year_match = re.search(r'\b(20\d{2})\b', parution)
                if year_match:
                    year = year_match.group(1)
                    stats['par_annee'][year] += 1
            except:
                pass
        
        # Statistiques couverture et r√©sum√©
        if book.get('couverture') and book['couverture'].strip():
            stats['avec_couverture'] += 1
        else:
            stats['sans_couverture'] += 1
            
        if book.get('resume') and book['resume'].strip():
            stats['avec_resume'] += 1
        else:
            stats['sans_resume'] += 1
    
    # Convertir defaultdict en dict normal pour la s√©rialisation JSON
    stats['par_categorie'] = dict(stats['par_categorie'])
    stats['par_editeur'] = dict(stats['par_editeur'])
    stats['par_langue'] = dict(stats['par_langue'])
    stats['par_annee'] = dict(stats['par_annee'])
    
    return stats

def main():
    """Fonction principale pour fusionner les fichiers JSON."""
    print("üîÑ D√©but de la fusion des fichiers JSON Pr√™t num√©rique...")
    print("=" * 60)
    
    # D√©finir les chemins (script ex√©cut√© depuis le dossier pretnumerique)
    pretnumerique_dir = Path(".")  # Dossier courant
    output_file = "../dbase/prenumerique_complet.json"
    stats_file = "../dbase/prenumerique_statistiques.json"
    
    # V√©rifier que le dossier pretnumerique existe
    if not pretnumerique_dir.exists():
        print(f"‚ùå Le dossier {pretnumerique_dir} n'existe pas.")
        return
    
    # Cr√©er le dossier dbase s'il n'existe pas
    Path("../dbase").mkdir(exist_ok=True)
    
    # Collecter tous les fichiers JSON
    json_files = list(pretnumerique_dir.glob("*.json"))
    
    if not json_files:
        print(f"‚ùå Aucun fichier JSON trouv√© dans {pretnumerique_dir}")
        return
    
    print(f"üìÅ {len(json_files)} fichiers JSON trouv√©s:")
    for file in sorted(json_files):
        print(f"   - {file.name}")
    print()
    
    # Fusionner tous les livres
    all_books = []
    file_stats = {}
    
    for json_file in sorted(json_files):
        print(f"‚è≥ Traitement de {json_file.name}...")
        
        books = load_json_file(json_file)
        valid_books = []
        
        for book in books:
            validated_book = validate_book_data(book, json_file.name)
            if validated_book:
                valid_books.append(validated_book)
        
        file_stats[json_file.name] = {
            'total_brut': len(books),
            'total_valide': len(valid_books),
            'categorie': get_category_from_filename(json_file.stem)
        }
        
        all_books.extend(valid_books)
        print(f"   ‚úÖ {len(valid_books)} livres valides sur {len(books)} trouv√©s")
    
    print(f"\nüìä R√âSULTATS DE LA FUSION:")
    print(f"   üìö Total de livres fusionn√©s: {len(all_books)}")
    print(f"   üìÅ Fichiers trait√©s: {len(json_files)}")
    
    # Supprimer les doublons
    unique_books, duplicates_found = remove_duplicates(all_books)
    
    # G√©n√©rer les statistiques
    print("\n‚è≥ G√©n√©ration des statistiques...")
    stats = generate_statistics(unique_books, duplicates_found)
    
    # Ajouter les statistiques par fichier
    stats['par_fichier'] = file_stats
    
    # Sauvegarder le fichier fusionn√© (avec les livres uniques)
    print(f"\nüíæ Sauvegarde dans {output_file}...")
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(unique_books, f, ensure_ascii=False, indent=2)
        print(f"   ‚úÖ Fichier fusionn√© sauvegard√©: {output_file}")
    except Exception as e:
        print(f"   ‚ùå Erreur lors de la sauvegarde: {e}")
        return
    
    # Sauvegarder les statistiques
    print(f"üíæ Sauvegarde des statistiques dans {stats_file}...")
    try:
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        print(f"   ‚úÖ Statistiques sauvegard√©es: {stats_file}")
    except Exception as e:
        print(f"   ‚ùå Erreur lors de la sauvegarde des statistiques: {e}")
    
    # Affichage des statistiques principales
    print(f"\nüìà STATISTIQUES PRINCIPALES:")
    print(f"   üìö Total de livres: {stats['total_livres']}")
    if 'deduplication' in stats:
        print(f"   üîÑ Doublons supprim√©s: {stats['deduplication']['doublons_trouves']}")
    print(f"   üè∑Ô∏è  Cat√©gories: {len(stats['par_categorie'])}")
    print(f"   üè¢ √âditeurs: {len(stats['par_editeur'])}")
    print(f"   üåç Langues: {len(stats['par_langue'])}")
    print(f"   üìÖ Ann√©es: {len(stats['par_annee'])}")
    print(f"   üñºÔ∏è  Avec couverture: {stats['avec_couverture']} ({stats['avec_couverture']/stats['total_livres']*100:.1f}%)")
    print(f"   üìñ Avec r√©sum√©: {stats['avec_resume']} ({stats['avec_resume']/stats['total_livres']*100:.1f}%)")
    
    # Top 10 des cat√©gories
    print(f"\nüèÜ TOP 10 DES CAT√âGORIES:")
    sorted_categories = sorted(stats['par_categorie'].items(), key=lambda x: x[1], reverse=True)
    for i, (cat, count) in enumerate(sorted_categories[:10], 1):
        print(f"   {i:2d}. {cat}: {count} livres")
    
    # Top 10 des √©diteurs
    print(f"\nüèÜ TOP 10 DES √âDITEURS:")
    sorted_editors = sorted(stats['par_editeur'].items(), key=lambda x: x[1], reverse=True)
    for i, (editor, count) in enumerate(sorted_editors[:10], 1):
        print(f"   {i:2d}. {editor}: {count} livres")
    
    print(f"\n" + "=" * 60)
    print(f"üéâ Fusion termin√©e avec succ√®s!")
    print(f"üìÑ Fichier fusionn√©: {output_file}")
    print(f"üìä Statistiques: {stats_file}")
    print(f"=" * 60)

if __name__ == "__main__":
    main()
