#!/usr/bin/env python3
"""
GÃ©nÃ©rateur de template de validation pour get_keywords_with_gpt
CrÃ©e des rÃ©sultats attendus basÃ©s sur l'analyse des requÃªtes sans appeler l'API
"""

import json
import re

def extract_queries_from_markdown():
    """Extrait toutes les requÃªtes du fichier EXEMPLES_REQUETES.md"""
    try:
        with open("../EXEMPLES_REQUETES.md", 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extraire les requÃªtes entre guillemets
        queries = re.findall(r'"([^"]+)"', content)
        
        # Filtrer et nettoyer
        filtered = []
        for q in queries:
            if len(q) > 5 and not q.startswith('{') and not '```' in q:
                filtered.append(q.strip())
        
        # Supprimer doublons en gardant l'ordre
        return list(dict.fromkeys(filtered))
        
    except FileNotFoundError:
        print("âŒ Fichier EXEMPLES_REQUETES.md non trouvÃ©")
        return []

def analyze_query(query):
    """
    Analyse une requÃªte et prÃ©dit ce que get_keywords_with_gpt devrait retourner
    """
    query_lower = query.lower()
    
    # Patterns pour dÃ©tecter les types de requÃªtes
    author_patterns = [
        r'livres?\s+de\s+([A-ZÃ€-Å¸][a-zÃ -Ã¿]+(?:\s+[A-ZÃ€-Å¸][a-zÃ -Ã¿]+)*)',
        r'Å“uvres?\s+(?:complÃ¨tes?\s+)?d[\'e]\s*([A-ZÃ€-Å¸][a-zÃ -Ã¿]+(?:\s+[A-ZÃ€-Å¸][a-zÃ -Ã¿]+)*)',
        r'romans?\s+de\s+([A-ZÃ€-Å¸][a-zÃ -Ã¿]+(?:\s+[A-ZÃ€-Å¸][a-zÃ -Ã¿]+)*)',
        r'tout\s+de\s+([A-ZÃ€-Å¸][a-zÃ -Ã¿]+(?:\s+[A-ZÃ€-Å¸][a-zÃ -Ã¿]+)*)'
    ]
    
    # VÃ©rifier si c'est une requÃªte auteur
    for pattern in author_patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            author_name = match.group(1)
            return {
                "keywords": {
                    "auteur": [author_name, author_name.split()[-1]]  # Nom complet + nom de famille
                }
            }
    
    # Genres littÃ©raires
    genre_mapping = {
        'science-fiction': ['science-fiction', 'sci-fi', 'SF', 'anticipation'],
        'fantasy': ['fantasy', 'fantastique', 'merveilleux', 'Ã©pique'],
        'thriller': ['thriller', 'suspense'],
        'policier': ['policier', 'polar', 'crime', 'enquÃªte'],
        'romance': ['romance', 'romantique', 'sentimental', 'amour'],
        'historique': ['historique', 'histoire', 'Ã©poque', 'pÃ©riode'],
        'biographie': ['biographie', 'vie de'],
        'dÃ©veloppement personnel': ['dÃ©veloppement personnel', 'self-help', 'croissance'],
        'philosophie': ['philosophie', 'mÃ©taphysique'],
        'cuisine': ['cuisine', 'culinaire', 'recettes']
    }
    
    for genre, keywords in genre_mapping.items():
        if any(keyword in query_lower for keyword in keywords):
            return {
                "keywords": {
                    "categorie": keywords
                }
            }
    
    # Langues
    if 'anglais' in query_lower:
        return {"keywords": {"langue": ["anglais", "english"]}}
    elif 'franÃ§ais' in query_lower and 'en franÃ§ais' in query_lower:
        return {"keywords": {"langue": ["franÃ§ais", "french"]}}
    elif 'espagnol' in query_lower:
        return {"keywords": {"langue": ["espagnol", "spanish"]}}
    elif 'italien' in query_lower:
        return {"keywords": {"langue": ["italien", "italian"]}}
    
    # Pages / format
    if 'moins de' in query_lower and 'pages' in query_lower:
        match = re.search(r'moins de (\d+) pages', query_lower)
        if match:
            return {"keywords": {"pages": [f"moins de {match.group(1)}", "court", "bref"]}}
    
    if 'plus de' in query_lower and 'pages' in query_lower:
        match = re.search(r'plus de (\d+) pages', query_lower)
        if match:
            return {"keywords": {"pages": [f"plus de {match.group(1)}", "volumineux", "long"]}}
    
    # Titres spÃ©cifiques
    known_titles = {
        'le petit prince': ['Le Petit Prince', 'Petit Prince'],
        '1984': ['1984', 'Nineteen Eighty-Four'],
        "l'Ã©tranger": ["L'Ã‰tranger", "Etranger"],
        'harry potter': ['Harry Potter', 'Potter'],
        'da vinci code': ['Da Vinci Code', 'Code Da Vinci']
    }
    
    for title_key, title_variants in known_titles.items():
        if title_key in query_lower:
            return {"keywords": {"titre": title_variants}}
    
    # ThÃ¨mes gÃ©nÃ©raux
    theme_mapping = {
        'intelligence artificielle': ['intelligence artificielle', 'IA', 'AI', 'technologie'],
        'seconde guerre mondiale': ['Seconde Guerre mondiale', 'WWII', 'guerre', '1939-1945'],
        'management': ['management', 'gestion', 'leadership', 'Ã©quipe'],
        'voyage': ['voyage', 'tourisme', 'guide', 'dÃ©couverte'],
        'art': ['art', 'peinture', 'sculpture', 'artistique']
    }
    
    for theme, keywords in theme_mapping.items():
        if theme in query_lower:
            return {"keywords": {"resume": keywords}}
    
    # Si aucun pattern spÃ©cifique, essayer de dÃ©tecter le champ principal
    if 'livre' in query_lower or 'roman' in query_lower:
        # Extraire le mot-clÃ© principal aprÃ¨s "de/sur"
        match = re.search(r'(?:de|sur)\s+([a-zÃ -Ã¿\s]+)', query_lower)
        if match:
            keyword = match.group(1).strip()
            return {"keywords": {"categorie": [keyword]}}
    
    # Fallback gÃ©nÃ©rique
    words = query_lower.replace('"', '').split()
    main_words = [w for w in words if len(w) > 3 and w not in ['livres', 'romans', 'cherche', 'veux', 'avez', 'vous', 'pour']]
    
    if main_words:
        return {"keywords": {"categorie": main_words[:3]}}
    
    return {"keywords": {"categorie": ["general"]}}

def generate_validation_data():
    """
    GÃ©nÃ¨re un fichier de validation avec les rÃ©sultats attendus
    """
    print("ğŸ¯ GÃ©nÃ©ration des donnÃ©es de validation pour get_keywords_with_gpt")
    print("=" * 65)
    
    # Extraire les requÃªtes
    queries = extract_queries_from_markdown()
    
    if not queries:
        print("âŒ Aucune requÃªte trouvÃ©e")
        return
    
    print(f"ğŸ“ Analyse de {len(queries)} requÃªtes...")
    
    validation_data = []
    
    for i, query in enumerate(queries, 1):
        print(f"[{i:2d}] {query}")
        
        # Analyser la requÃªte
        expected_result = analyze_query(query)
        print(f"    â†’ {json.dumps(expected_result, ensure_ascii=False)}")
        
        # CrÃ©er l'entrÃ©e de validation
        validation_entry = {
            "query": query,
            "expected_result": expected_result,
            "analysis_notes": "",  # Ã€ remplir manuellement si nÃ©cessaire
            "priority": "normal",  # normal, high, low
            "test_category": classify_test_category(query),
            "validation_status": "to_validate"  # to_validate, validated, needs_review
        }
        
        validation_data.append(validation_entry)
    
    # CrÃ©er le fichier de validation complet
    output = {
        "metadata": {
            "generation_date": "2025-08-08",
            "function_tested": "get_keywords_with_gpt",
            "total_test_cases": len(validation_data),
            "description": "DonnÃ©es de validation gÃ©nÃ©rÃ©es automatiquement basÃ©es sur l'analyse des requÃªtes"
        },
        "test_guidelines": {
            "validation_criteria": [
                "Le champ sÃ©lectionnÃ© est-il le plus appropriÃ© pour la requÃªte?",
                "Les mots-clÃ©s extraits sont-ils pertinents et complets?",
                "Les synonymes/variantes sont-ils appropriÃ©s?",
                "Le format JSON est-il correct et cohÃ©rent?"
            ],
            "field_priorities": {
                "auteur": "PrioritÃ© haute - noms d'auteurs explicites",
                "titre": "PrioritÃ© haute - titres de livres spÃ©cifiques", 
                "categorie": "PrioritÃ© moyenne - genres et catÃ©gories",
                "langue": "PrioritÃ© moyenne - langues spÃ©cifiÃ©es",
                "resume": "PrioritÃ© basse - thÃ¨mes et concepts gÃ©nÃ©raux",
                "pages": "PrioritÃ© basse - critÃ¨res de format"
            }
        },
        "test_cases": validation_data
    }
    
    # Sauvegarder
    with open("keywords_validation_expected.json", 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    # Statistiques
    categories = {}
    for entry in validation_data:
        cat = entry["test_category"]
        categories[cat] = categories.get(cat, 0) + 1
    
    print(f"\nğŸ“Š Statistiques:")
    for cat, count in categories.items():
        print(f"   {cat}: {count} requÃªtes")
    
    print(f"\nğŸ’¾ Fichier gÃ©nÃ©rÃ©: keywords_validation_expected.json")
    print(f"\nğŸ“‹ Prochaines Ã©tapes:")
    print("1. Examiner le fichier gÃ©nÃ©rÃ©")
    print("2. Ajuster manuellement les rÃ©sultats attendus si nÃ©cessaire")
    print("3. Utiliser ce fichier comme rÃ©fÃ©rence pour les tests")
    print("4. ImplÃ©menter un script de validation automatique")

def classify_test_category(query):
    """Classifie le type de test pour organiser les validations"""
    query_lower = query.lower()
    
    if any(word in query_lower for word in ['de ', 'Å“uvres', 'tout de']):
        if any(name.istitle() for name in query.split()):
            return "author_query"
    
    if any(word in query_lower for word in ['romans', 'livres']):
        if any(genre in query_lower for genre in ['science-fiction', 'fantasy', 'policier', 'romance', 'thriller']):
            return "genre_query"
    
    if any(word in query_lower for word in ['anglais', 'franÃ§ais', 'espagnol', 'italien']):
        return "language_query"
    
    if 'pages' in query_lower:
        return "format_query"
    
    if query.startswith('"') and query.endswith('"'):
        return "title_query"
    
    if any(word in query_lower for word in ['sur', 'traitant', 'parlent']):
        return "theme_query"
    
    return "general_query"

if __name__ == "__main__":
    generate_validation_data()
