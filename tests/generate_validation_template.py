#!/usr/bin/env python3
"""
G√©n√©rateur de template de validation pour get_keywords_with_gpt
Cr√©e des r√©sultats attendus bas√©s sur l'analyse des requ√™tes sans appeler l'API
"""

import json
import re

def extract_queries_from_markdown():
    """Extrait toutes les requ√™tes du fichier EXEMPLES_REQUETES.md"""
    try:
        with open("../EXEMPLES_REQUETES.md", 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extraire les requ√™tes entre guillemets
        queries = re.findall(r'"([^"]+)"', content)
        
        # Filtrer et nettoyer
        filtered = []
        for q in queries:
            if len(q) > 5 and not q.startswith('{') and not '```' in q:
                filtered.append(q.strip())
        
        # Supprimer doublons en gardant l'ordre
        return list(dict.fromkeys(filtered))
        
    except FileNotFoundError:
        print("‚ùå Fichier EXEMPLES_REQUETES.md non trouv√©")
        return []

def analyze_query(query):
    """
    Analyse une requ√™te et pr√©dit ce que get_keywords_with_gpt devrait retourner
    """
    query_lower = query.lower()
    
    # Patterns pour d√©tecter les types de requ√™tes
    author_patterns = [
        r'livres?\s+de\s+([A-Z√Ä-≈∏][a-z√†-√ø]+(?:\s+[A-Z√Ä-≈∏][a-z√†-√ø]+)*)',
        r'≈ìuvres?\s+(?:compl√®tes?\s+)?d[\'e]\s*([A-Z√Ä-≈∏][a-z√†-√ø]+(?:\s+[A-Z√Ä-≈∏][a-z√†-√ø]+)*)',
        r'romans?\s+de\s+([A-Z√Ä-≈∏][a-z√†-√ø]+(?:\s+[A-Z√Ä-≈∏][a-z√†-√ø]+)*)',
        r'tout\s+de\s+([A-Z√Ä-≈∏][a-z√†-√ø]+(?:\s+[A-Z√Ä-≈∏][a-z√†-√ø]+)*)'
    ]
    
    # V√©rifier si c'est une requ√™te auteur
    for pattern in author_patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            author_name = match.group(1)
            return {
                "keywords": {
                    "auteur": [author_name, author_name.split()[-1]]  # Nom complet + nom de famille
                }
            }
    
    # Genres litt√©raires
    genre_mapping = {
        'science-fiction': ['science-fiction', 'sci-fi', 'SF', 'anticipation'],
        'fantasy': ['fantasy', 'fantastique', 'merveilleux', '√©pique'],
        'thriller': ['thriller', 'suspense'],
        'policier': ['policier', 'polar', 'crime', 'enqu√™te'],
        'romance': ['romance', 'romantique', 'sentimental', 'amour'],
        'historique': ['historique', 'histoire', '√©poque', 'p√©riode'],
        'biographie': ['biographie', 'vie de'],
        'd√©veloppement personnel': ['d√©veloppement personnel', 'self-help', 'croissance'],
        'philosophie': ['philosophie', 'm√©taphysique'],
        'cuisine': ['cuisine', 'culinaire', 'recettes']
    }
    
    for genre, keywords in genre_mapping.items():
        if any(keyword in query_lower for keyword in keywords):
            return {
                "keywords": {
                    "categorie": keywords
                }
            }
    
    # Langues
    if 'anglais' in query_lower:
        return {"keywords": {"langue": ["anglais", "english"]}}
    elif 'fran√ßais' in query_lower and 'en fran√ßais' in query_lower:
        return {"keywords": {"langue": ["fran√ßais", "french"]}}
    elif 'espagnol' in query_lower:
        return {"keywords": {"langue": ["espagnol", "spanish"]}}
    elif 'italien' in query_lower:
        return {"keywords": {"langue": ["italien", "italian"]}}
    
    # Pages / format
    if 'moins de' in query_lower and 'pages' in query_lower:
        match = re.search(r'moins de (\d+) pages', query_lower)
        if match:
            return {"keywords": {"pages": [f"moins de {match.group(1)}", "court", "bref"]}}
    
    if 'plus de' in query_lower and 'pages' in query_lower:
        match = re.search(r'plus de (\d+) pages', query_lower)
        if match:
            return {"keywords": {"pages": [f"plus de {match.group(1)}", "volumineux", "long"]}}
    
    # Titres sp√©cifiques
    known_titles = {
        'le petit prince': ['Le Petit Prince', 'Petit Prince'],
        '1984': ['1984', 'Nineteen Eighty-Four'],
        "l'√©tranger": ["L'√âtranger", "Etranger"],
        'harry potter': ['Harry Potter', 'Potter'],
        'da vinci code': ['Da Vinci Code', 'Code Da Vinci']
    }
    
    for title_key, title_variants in known_titles.items():
        if title_key in query_lower:
            return {"keywords": {"titre": title_variants}}
    
    # Th√®mes g√©n√©raux
    theme_mapping = {
        'intelligence artificielle': ['intelligence artificielle', 'IA', 'AI', 'technologie'],
        'seconde guerre mondiale': ['Seconde Guerre mondiale', 'WWII', 'guerre', '1939-1945'],
        'management': ['management', 'gestion', 'leadership', '√©quipe'],
        'voyage': ['voyage', 'tourisme', 'guide', 'd√©couverte'],
        'art': ['art', 'peinture', 'sculpture', 'artistique']
    }
    
    for theme, keywords in theme_mapping.items():
        if theme in query_lower:
            return {"keywords": {"resume": keywords}}
    
    # Si aucun pattern sp√©cifique, essayer de d√©tecter le champ principal
    if 'livre' in query_lower or 'roman' in query_lower:
        # Extraire le mot-cl√© principal apr√®s "de/sur"
        match = re.search(r'(?:de|sur)\s+([a-z√†-√ø\s]+)', query_lower)
        if match:
            keyword = match.group(1).strip()
            return {"keywords": {"categorie": [keyword]}}
    
    # Fallback g√©n√©rique
    words = query_lower.replace('"', '').split()
    main_words = [w for w in words if len(w) > 3 and w not in ['livres', 'romans', 'cherche', 'veux', 'avez', 'vous', 'pour']]
    
    if main_words:
        return {"keywords": {"categorie": main_words[:3]}}
    
    return {"keywords": {"categorie": ["general"]}}

def generate_validation_data():
    """
    G√©n√®re un fichier de validation avec les r√©sultats attendus
    """
    print("üéØ G√©n√©ration des donn√©es de validation pour get_keywords_with_gpt")
    print("=" * 65)
    
    # Extraire les requ√™tes
    queries = extract_queries_from_markdown()
    
    if not queries:
        print("‚ùå Aucune requ√™te trouv√©e")
        return
    
    print(f"üìù Analyse de {len(queries)} requ√™tes...")
    
    validation_data = []
    
    for i, query in enumerate(queries, 1):
        print(f"[{i:2d}] {query}")
        
        # Analyser la requ√™te
        expected_result = analyze_query(query)
        print(f"    ‚Üí {json.dumps(expected_result, ensure_ascii=False)}")
        
        # Cr√©er l'entr√©e de validation
        validation_entry = {
            "query": query,
            "expected_result": expected_result,
            "analysis_notes": "",  # √Ä remplir manuellement si n√©cessaire
            "priority": "normal",  # normal, high, low
            "test_category": classify_test_category(query),
            "validation_status": "to_validate"  # to_validate, validated, needs_review
        }
        
        validation_data.append(validation_entry)
    
    # Cr√©er le fichier de validation complet
    output = {
        "metadata": {
            "generation_date": "2025-08-08",
            "function_tested": "get_keywords_with_gpt",
            "total_test_cases": len(validation_data),
            "description": "Donn√©es de validation g√©n√©r√©es automatiquement bas√©es sur l'analyse des requ√™tes"
        },
        "test_guidelines": {
            "validation_criteria": [
                "Le champ s√©lectionn√© est-il le plus appropri√© pour la requ√™te?",
                "Les mots-cl√©s extraits sont-ils pertinents et complets?",
                "Les synonymes/variantes sont-ils appropri√©s?",
                "Le format JSON est-il correct et coh√©rent?"
            ],
            "field_priorities": {
                "auteur": "Priorit√© haute - noms d'auteurs explicites",
                "titre": "Priorit√© haute - titres de livres sp√©cifiques", 
                "categorie": "Priorit√© moyenne - genres et cat√©gories",
                "langue": "Priorit√© moyenne - langues sp√©cifi√©es",
                "resume": "Priorit√© basse - th√®mes et concepts g√©n√©raux",
                "pages": "Priorit√© basse - crit√®res de format"
            }
        },
        "test_cases": validation_data
    }
    
    # Sauvegarder
    with open("keywords_validation_expected.json", 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    # Statistiques
    categories = {}
    for entry in validation_data:
        cat = entry["test_category"]
        categories[cat] = categories.get(cat, 0) + 1
    
    print(f"\nüìä Statistiques:")
    for cat, count in categories.items():
        print(f"   {cat}: {count} requ√™tes")
    
    print(f"\nüíæ Fichier g√©n√©r√©: keywords_validation_expected.json")
    print(f"\nüìã Prochaines √©tapes:")
    print("1. Examiner le fichier g√©n√©r√©")
    print("2. Ajuster manuellement les r√©sultats attendus si n√©cessaire")
    print("3. Utiliser ce fichier comme r√©f√©rence pour les tests")
    print("4. Impl√©menter un script de validation automatique")

def classify_test_category(query):
    """Classifie le type de test pour organiser les validations"""
    query_lower = query.lower()
    
    if any(word in query_lower for word in ['de ', '≈ìuvres', 'tout de']):
        if any(name.istitle() for name in query.split()):
            return "author_query"
    
    if any(word in query_lower for word in ['romans', 'livres']):
        if any(genre in query_lower for genre in ['science-fiction', 'fantasy', 'policier', 'romance', 'thriller']):
            return "genre_query"
    
    if any(word in query_lower for word in ['anglais', 'fran√ßais', 'espagnol', 'italien']):
        return "language_query"
    
    if 'pages' in query_lower:
        return "format_query"
    
    if query.startswith('"') and query.endswith('"'):
        return "title_query"
    
    if any(word in query_lower for word in ['sur', 'traitant', 'parlent']):
        return "theme_query"
    
    return "general_query"

if __name__ == "__main__":
    generate_validation_data()
