# Guide de Test BiblioSense

## ğŸ“‹ Fichiers de Test

### 1. `EXEMPLES_REQUETES.md`
Guide complet avec des exemples de requÃªtes utilisateurs organisÃ©s par catÃ©gorie :
- Recherches par genre (fiction, non-fiction)
- Recherches par auteur
- Recherches thÃ©matiques
- RequÃªtes complexes
- Recherches par humeur/mood

### 2. `test_queries.json` 
20 requÃªtes de test structurÃ©es avec mÃ©tadonnÃ©es pour tests automatisÃ©s.

### 3. `test_api.py`
Script Python pour tester automatiquement l'API avec toutes les requÃªtes.

### 4. `demo_interactive.py`
DÃ©monstration interactive permettant de tester manuellement des requÃªtes.

## ğŸš€ Comment Utiliser

### Test Automatique
```bash
# Lancer votre application BiblioSense
python app.py

# Dans un autre terminal, lancer les tests
python test_api.py
```

### DÃ©monstration Interactive
```bash
# Lancer la dÃ©mo interactive
python demo_interactive.py

# Ou avec une URL personnalisÃ©e
python demo_interactive.py https://your-service.run.app
```

## ğŸ“Š RÃ©sultats des Tests

Les tests automatiques gÃ©nÃ¨rent un fichier `test_results.json` avec :
- Timestamp des tests
- Nombre de tests rÃ©ussis/Ã©chouÃ©s
- Temps de rÃ©ponse
- Nombre de livres trouvÃ©s par requÃªte
- Messages d'erreur dÃ©taillÃ©s

## ğŸ¯ Exemples de RequÃªtes Populaires

### Simple
- "Je cherche des romans de science-fiction"
- "Livres de Victor Hugo"
- "Le Petit Prince"

### Complexe
- "Roman policier franÃ§ais publiÃ© aprÃ¨s 2020"
- "Livre de cuisine vÃ©gÃ©tarienne de moins de 300 pages"
- "Biographies d'entrepreneures femmes"

### Par Humeur
- "Je veux quelque chose de lÃ©ger et drÃ´le"
- "Un livre pour me motiver"
- "Romans tristes qui font pleurer"

## ğŸ”§ Configuration

### URL de Test
Modifiez la variable `base_url` dans les scripts :
- Local: `http://localhost:8080`
- Cloud Run: `https://your-service.run.app`

### Timeout
Les scripts utilisent un timeout de 30 secondes pour les requÃªtes GPT.

## ğŸ“ˆ MÃ©triques Ã  Surveiller

1. **Taux de succÃ¨s** : % de requÃªtes qui retournent des rÃ©sultats
2. **Temps de rÃ©ponse** : Latence moyenne des requÃªtes
3. **Pertinence** : Nombre moyen de livres trouvÃ©s
4. **Couverture** : DiversitÃ© des catÃ©gories testÃ©es

## ğŸ› DÃ©pannage

### "Connection refused"
- VÃ©rifiez que l'application est lancÃ©e
- VÃ©rifiez l'URL et le port

### "Timeout"
- Les requÃªtes GPT peuvent Ãªtre lentes
- Augmentez le timeout si nÃ©cessaire

### "No results"
- VÃ©rifiez que la base de donnÃ©es contient des livres
- VÃ©rifiez la clÃ© API OpenAI

## ğŸ“ Ajouter de Nouveaux Tests

Pour ajouter une nouvelle requÃªte de test, modifiez `test_queries.json` :

```json
{
  "id": 21,
  "category": "nouvelle_categorie",
  "query": "Votre nouvelle requÃªte",
  "expected_keywords": ["mot-clÃ©1", "mot-clÃ©2"],
  "expected_categories": ["CatÃ©gorie1", "CatÃ©gorie2"]
}
```
